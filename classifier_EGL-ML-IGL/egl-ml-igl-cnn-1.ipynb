{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Import modules"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# General\nimport os\nimport random\n\n# Data processing, storage\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Image processing\nimport cv2 # opencv-python\nfrom PIL import Image\n\n# Data plotting\nimport matplotlib.pyplot as plt\n\n# Machine learning\nimport tensorflow as tf\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Check input data availability"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    print(dirname, \"contains\", len(filenames), \"files.\")\n    #for filename in filenames:\n    #    print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Set parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"basedatadir = '/kaggle/input/p7eglmligltilesshiftrotate/P7-EGL-ML-IGL-tiles-shift-rotate'\n\ntrain_data_dir = basedatadir + '/train'\ntest_data_dir = basedatadir + '/test'\n\n# Calculation of max batch size-\n# Max batch size= available GPU memory bytes / 4 / (size of tensors + trainable parameters)\n# size of tensors = batch_size*100*100 *4 if using 64 bit integers\n\nbatch_size = 256\ntest_batch_size = 256\nimg_height = 300\nimg_width = 300\nmean = 157.1\nstd = 64.6\nAUTOTUNE = tf.data.experimental.AUTOTUNE","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create FileList datasets\ntf.data.Dataset.list_files() creates a dataset from a directory list of files using a matching pattern."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_list_ds = tf.data.Dataset.list_files(str(train_data_dir + '/*/*'), shuffle=False)\n# get the count of image files in the train directory\ntrain_image_count=0\nfor dir1 in os.listdir(train_data_dir):\n    for files in os.listdir(os.path.join(train_data_dir, dir1)):\n        train_image_count+=1\ntrain_list_ds = train_list_ds.shuffle(train_image_count, reshuffle_each_iteration=False)\nprint(train_image_count)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print some filenames\nfor x in train_list_ds.take(5):\n    print(x.numpy().decode('utf-8'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_list_ds = tf.data.Dataset.list_files(str(test_data_dir + '/*/*'), shuffle=False)\n# get the count of image files in the train directory\ntest_image_count=0\nfor dir1 in os.listdir(test_data_dir):\n    for files in os.listdir(os.path.join(test_data_dir, dir1)):\n        test_image_count+=1\ntest_list_ds = test_list_ds.shuffle(test_image_count, reshuffle_each_iteration=False)\nprint(test_image_count)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print some filenames\nfor x in test_list_ds.take(5):\n    print(x.numpy().decode('utf-8'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Function to create list of files from tensorflow dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use this function to list files from a filelist dataset, such as test_list_ds.\n# This may be useful later\nlist_files_from_tfdataset = lambda tfd: [f.numpy().decode('utf-8') for f in tfd]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#l = list_files_from_tfdataset(test_list_ds)\n#print(len(l))\n#del(l)\n#test_ds_filepaths = test_list_ds.take(test_image_count)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create class labels from the directory name"},{"metadata":{"trusted":true},"cell_type":"code","source":"class_names = np.array(sorted([dir1 for dir1 in os.listdir(train_data_dir)]))\nclass_names","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Split the dataset into train and val (Note that test dataset is already kept separate)\nThe validation dataset is 30% of the total dataset, and train dataset is 70% of the entire dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create training and validation datasets\nval_size = int(train_image_count * 0.3)\ntrain_ds = train_list_ds.skip(val_size)\nval_ds = train_list_ds.take(val_size)\nprint(\"Training images:\", train_image_count-val_size, \"\\nValidation images:\", val_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Different way of creatint training and validation datasets\n# This is useful to select only small subset of the full data\n#val_size = int(train_image_count * 0.01)\n#train_size = int(train_image_count * 0.03)\n#train_ds = train_list_ds.take(train_size)\n#remaining_list_ds = train_list_ds.skip(train_size)\n#val_ds = remaining_list_ds.take(val_size)\n#print(\"Training images:\", train_size, \"\\nValidation images:\", val_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create test dataset\ntest_ds = test_list_ds.take(test_image_count)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print some filenames\nprint(\"Files from train_ds\")\nfor x in train_ds.take(3):\n    print(x.numpy().decode('utf-8'))\nprint(\"Files from val_ds\")\nfor x in val_ds.take(3):\n    print(x.numpy().decode('utf-8'))\nprint(\"Files from test_ds\")\nfor x in test_ds.take(3):\n    print(x.numpy().decode('utf-8'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create input pipeline components for a single training/validation example,<br>where a pair of tensors represents the image and its corresponding label."},{"metadata":{"trusted":true},"cell_type":"code","source":"#To process the label\ndef get_label(filepath):\n    # convert the path to a list of path components separated by sep\n    parts = tf.strings.split(filepath, os.path.sep)\n    # The second to last is the class-directory\n    one_hot = parts[-2] == class_names\n    # Integer encode the label\n    return tf.argmax(tf.cast(one_hot, tf.int32))\n    \n    #label = tf.strings.split(filepath, sep='/')\n    #label = tf.strings.split(label[-1], sep='.')\n\n# To process the image\ndef decode_img(img):\n    # convert the compressed string to a 3D uint8 tensor\n    #img = tf.image.decode_jpeg(img, channels=3)\n    img = tf.image.decode_png(img, channels=1)\n    # resize the image to the desired size\n    return tf.image.resize(img, [img_height, img_width])\n\n# To create the single training of validation example with image and its corresponding label\ndef process_path(filepath):\n    label = get_label(filepath)\n    # load the raw data from the file as a string\n    img = tf.io.read_file(filepath)\n    img = decode_img(img)\n    return img, label","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create tf dataset of tensor by mapping the above functions to the filelist datasets<br>\nSet the AUTOTUNE. This will help to delegate the decision on the level of parallelism<br>to use to the tf.data at runtime to optimize the CPU/GPU utilization."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\ntrain_ds = train_ds.map(process_path, num_parallel_calls=AUTOTUNE)\nval_ds = val_ds.map(process_path, num_parallel_calls=AUTOTUNE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\ntest_ds = test_ds.map(process_path, num_parallel_calls=AUTOTUNE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test if the datasets are prepared correctly\nfor images, labels in train_ds.take(1):\n    print(images.shape, labels.shape)\n    img = images[0].numpy()\n    print(img.min(), img.max(), img.dtype, labels.numpy())\n    img = (img-5)/2 # Testing mathematical operations on tensor\n    print(img.min(), img.max(), img.dtype, labels.numpy())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Set augmentation and normalization functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def augment(image, label):\n    img = tf.image.rot90(image)\n    img = tf.image.flip_left_right(img)\n    #img = tf.clip_by_value(img, 0.0, 1.0)\n    return img, label\n\ndef standardize_per_image(image, label):\n    img = tf.image.per_image_standardization(image)\n    return img, label\n\ndef standardize_dataset(image, label):\n    # NOTE: mean and std have to be defined globally\n    # Not checking that mean and std are > 0 to avoid time lag. So be careful with the values of mean and std.\n    img = (image - mean)/std\n    return img, label","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Configure data source for Performance\nTo configure the data source for performance, use prefetching. Prefetching in tf.data allows the preprocessing of the data and model execution of a training step to overlap. While the model is executing a training step 100, the input pipeline is reading the data for step 101."},{"metadata":{"trusted":true},"cell_type":"code","source":"def configure_for_performance(ds, cache_filename=''):\n    if cache_filename == '':\n        ds = ds.cache()\n    else:\n        ds = ds.cache(cache_filename)\n    ds = ds.shuffle(buffer_size=1000)\n    #ds = ds.map(augment, num_parallel_calls=AUTOTUNE) # No need if pre-augmented images.\n    #ds = ds.map(standardize_per_image, num_parallel_calls=AUTOTUNE) # Use either of the two standardizations.\n    ds = ds.map(standardize_dataset, num_parallel_calls=AUTOTUNE)\n    ds = ds.batch(batch_size)\n    ds = ds.prefetch(buffer_size=AUTOTUNE)\n    return ds\n\ntrain_ds = configure_for_performance(train_ds, cache_filename='')#, '/home/harsh/tensorflow_cache/train_v5.train_ds')\nval_ds = configure_for_performance(val_ds, cache_filename='')#, '/home/harsh/tensorflow_cache/train_v5.val_ds')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def configure_for_performance_forTestDataset(ds, cache_filename=''):\n    if cache_filename == '':\n        ds = ds.cache()\n    else:\n        ds = ds.cache(cache_filename)\n    #ds = ds.shuffle(buffer_size=1000)\n    #ds = ds.map(standardize_per_image, num_parallel_calls=AUTOTUNE) # Use either of the two standardizations.\n    ds = ds.map(standardize_dataset, num_parallel_calls=AUTOTUNE)\n    ds = ds.batch(test_batch_size)\n    ds = ds.prefetch(buffer_size=AUTOTUNE)\n    return ds\n\ntest_ds = configure_for_performance_forTestDataset(test_ds, cache_filename='')#, '/home/harsh/tensorflow_cache/train_v5.test_ds')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test that the pixels values are actually standardized and the images are properly stored.\nfor images, labels in train_ds.take(1):\n    print(images.shape, labels.shape)\n    img = images[0].numpy()\n    print(img.min(), img.max(), img.dtype, labels[0].numpy())\n    plt.imshow(img, cmap=plt.get_cmap(\"gray\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the test dataset. This dataset is not shuffled.\n# So you should see same values printed if you run it again.\nfor images, labels in test_ds.take(1):\n    print(images.shape, labels.shape)\n    #img = images[0].numpy()\n    print(images[0].numpy().min(), images[0].numpy().max())\n    print(images[100].numpy().min(), images[1].numpy().max())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check if the file names can be matched with output of the test dataset\ntest_ds_filelist = list_files_from_tfdataset(test_list_ds) # Create test dataset file list.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Choose an image and it's filename from the dataset.\n# Plot the tensor image as well as image given by the filename to see if they match.\nfor images, labels in test_ds.take(1):\n    print(images.shape, labels.shape)\n    #plt.imshow(images[2].numpy()[:,:], cmap=plt.get_cmap(\"gray\"))\n    print(images[2].numpy().shape, labels[2].numpy().shape)\n    print(\"Class label:\", labels[2].numpy())\n    print(\"Class name:\", class_names[labels[2].numpy()])\n    print(\"File name:\", test_ds_filelist[2])\n\nf = plt.figure()\n\nf.add_subplot(1,2, 1)\ntest_img = cv2.imread(test_ds_filelist[2], 0)\nplt.imshow(images[2].numpy()[:,:], cmap=plt.get_cmap(\"gray\"))\n\nf.add_subplot(1,2, 2)\nplt.imshow(test_img, cmap=plt.get_cmap(\"gray\"))\n\nplt.show(block=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check if a batch of images from test dataset can be printed along with classnames and filenames\nplt.figure(figsize=(35, 35))\ncnt = 0\nfor images, labels in train_ds.take(1):\n    #print(images.shape)\n    for i in range(batch_size):\n        ax = plt.subplot(int(np.sqrt(batch_size)), int(np.sqrt(batch_size)), i + 1)\n        #ax = plt.subplot(16, 16, i + 1)\n        #print(images[i].shape)\n        plt.imshow(images[i].numpy(), cmap=plt.get_cmap(\"gray\"))\n        plt.title(class_names[labels[i]])\n        #plt.title(class_names[labels[i]]+\"\\n\"+test_ds_filelist[i+cnt*batch_size].split(\"/\")[-1].replace(\".png\",\"\"))\n        plt.axis(\"off\")\n    cnt += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}