{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference- \"Input Pipeline for Images using Keras and TensorFlow - Guide to creating an input pipeline for custom image dataset for deep learning models using Keras and TensorFlow\" by Renu Khandelwal (Aug 21)\n",
    "https://towardsdatascience.com/input-pipeline-for-images-using-keras-and-tensorflow-c5e107b6d7b9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the GPU memory growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Taken from- https://github.com/tensorflow/tensorflow/issues/34695\n",
    "### This was done to resolve the error: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. [Op:Conv2D]\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full dataset\n",
    "train_data_dir=r'data_mip3_aug/train'\n",
    "test_data_dir=r'data_mip3_aug/test'\n",
    "\n",
    "# Calculation of max batch size-\n",
    "# Max batch size= available GPU memory bytes / 4 / (size of tensors + trainable parameters)\n",
    "# size of tensors = batch_size*100*100 *4 if using 64 bit integers\n",
    "\n",
    "batch_size = 256\n",
    "test_batch_size = 256\n",
    "img_height = 100\n",
    "img_width = 100\n",
    "mean = 157.1\n",
    "std = 64.6\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create filelist datasets\n",
    "### tf.data.Dataset.list_files() creates a dataset from a directory list of files using a matching pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list_ds = tf.data.Dataset.list_files(str(train_data_dir + '/*/*'), shuffle=False)\n",
    "# get the count of image files in the train directory\n",
    "train_image_count=0\n",
    "for dir1 in os.listdir(train_data_dir):\n",
    "    for files in os.listdir(os.path.join(train_data_dir, dir1)):\n",
    "        train_image_count+=1\n",
    "train_list_ds = train_list_ds.shuffle(train_image_count, reshuffle_each_iteration=False)\n",
    "print(train_image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some filenames\n",
    "for x in train_list_ds.take(5):\n",
    "    print(x.numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list_ds = tf.data.Dataset.list_files(str(test_data_dir + '/*/*'), shuffle=False)\n",
    "# get the count of image files in the train directory\n",
    "test_image_count=0\n",
    "for dir1 in os.listdir(test_data_dir):\n",
    "    for files in os.listdir(os.path.join(test_data_dir, dir1)):\n",
    "        test_image_count+=1\n",
    "test_list_ds = test_list_ds.shuffle(test_image_count, reshuffle_each_iteration=False)\n",
    "print(test_image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this function to list files from a filelist dataset, such as test_list_ds.\n",
    "# This may be useful later\n",
    "list_files_from_tfdataset = lambda tfd: [f.numpy().decode('utf-8') for f in tfd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#l = list_files_from_tfdataset(test_list_ds)\n",
    "#print(len(l))\n",
    "#del(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_ds_filepaths = test_list_ds.take(test_image_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating class labels from the directory name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = np.array(sorted([dir1 for dir1 in os.listdir(train_data_dir)]))\n",
    "class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset into train, and Val.\n",
    "The validation dataset is 30% of the total dataset, and train dataset is 70% of the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and validation datasets\n",
    "val_size = int(train_image_count * 0.3)\n",
    "train_ds = train_list_ds.skip(val_size)\n",
    "val_ds = train_list_ds.take(val_size)\n",
    "print(train_image_count-val_size, val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different way of creatint training and validation datasets\n",
    "# This is useful to select only small subset of the full data\n",
    "#val_size = int(train_image_count * 0.01)\n",
    "#train_size = int(train_image_count * 0.03)\n",
    "#train_ds = train_list_ds.take(train_size)\n",
    "#remaining_list_ds = train_list_ds.skip(train_size)\n",
    "#val_ds = remaining_list_ds.take(val_size)\n",
    "#print(train_size, val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some filenames\n",
    "for x in train_ds.take(5):\n",
    "    print(x.numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test dataset\n",
    "test_ds = test_list_ds.take(test_image_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating input pipeline components for a single training/validation example representing a pair of tensors to represent the image and its corresponding label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To process the label\n",
    "def get_label(filepath):\n",
    "    # convert the path to a list of path components separated by sep\n",
    "    parts = tf.strings.split(filepath, os.path.sep)\n",
    "    # The second to last is the class-directory\n",
    "    one_hot = parts[-2] == class_names\n",
    "    # Integer encode the label\n",
    "    return tf.argmax(tf.cast(one_hot, tf.int32))\n",
    "    \n",
    "    #label = tf.strings.split(filepath, sep='/')\n",
    "    #label = tf.strings.split(label[-1], sep='.')\n",
    "\n",
    "# To process the image\n",
    "def decode_img(img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    #img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.decode_png(img, channels=1)\n",
    "    # resize the image to the desired size\n",
    "    return tf.image.resize(img, [img_height, img_width])\n",
    "\n",
    "# To create the single training of validation example with image and its corresponding label\n",
    "def process_path(filepath):\n",
    "    label = get_label(filepath)\n",
    "    # load the raw data from the file as a string\n",
    "    img = tf.io.read_file(filepath)\n",
    "    img = decode_img(img)\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the AUTOTUNE; this will help to delegate the decision on the level of parallelism to use to the tf.data at runtime to optimize the CPU/GPU utilization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
    "train_ds = train_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "val_ds = val_ds.map(process_path, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = test_ds.map(process_path, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if the datasets are prepared correctly\n",
    "for images, labels in train_ds.take(1):\n",
    "    print(images.shape, labels.shape)\n",
    "    img = images[0].numpy()\n",
    "    print(img.min(), img.max(), img.dtype, labels.numpy())\n",
    "    img = (img-5)/2 # Testing mathematical operations on tensor\n",
    "    print(img.min(), img.max(), img.dtype, labels.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set augmentation and normalization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(image, label):\n",
    "    img = tf.image.rot90(image)\n",
    "    img = tf.image.flip_left_right(img)\n",
    "    #img = tf.clip_by_value(img, 0.0, 1.0)\n",
    "    return img, label\n",
    "\n",
    "def standardize_per_image(image, label):\n",
    "    img = tf.image.per_image_standardization(image)\n",
    "    return img, label\n",
    "\n",
    "def standardize_dataset(image, label):\n",
    "    # NOTE: mean and std have to be defined globally\n",
    "    # Not checking that mean and std are > 0 to avoid time lag. So be careful with the values of mean and std.\n",
    "    img = (image - mean)/std\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure data source for Performance\n",
    "To configure the data source for performance, use prefetching.\n",
    "Prefetching in tf.data allows the preprocessing of the data and model execution of a training step to overlap.\n",
    "While the model is executing a training step 100, the input pipeline is reading the data for step 101."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_for_performance(ds, cache_filename):\n",
    "    #ds = ds.cache()\n",
    "    ds = ds.cache(cache_filename)\n",
    "    ds = ds.shuffle(buffer_size=1000)\n",
    "    #ds = ds.map(augment, num_parallel_calls=AUTOTUNE) # No need if pre-augmented images.\n",
    "    #ds = ds.map(standardize_per_image, num_parallel_calls=AUTOTUNE) # Use either of the two standardizations.\n",
    "    ds = ds.map(standardize_dataset, num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "train_ds = configure_for_performance(train_ds, '/home/harsh/tensorflow_cache/train_v5.train_ds')\n",
    "val_ds = configure_for_performance(val_ds, '/home/harsh/tensorflow_cache/train_v5.val_ds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_for_performance_forTestDataset(ds, cache_filename):\n",
    "    #ds = ds.cache()\n",
    "    ds = ds.cache(cache_filename)\n",
    "    #ds = ds.shuffle(buffer_size=1000)\n",
    "    #ds = ds.map(standardize_per_image, num_parallel_calls=AUTOTUNE) # Use either of the two standardizations.\n",
    "    ds = ds.map(standardize_dataset, num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.batch(test_batch_size)\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "test_ds = configure_for_performance_forTestDataset(test_ds, '/home/harsh/tensorflow_cache/train_v5.test_ds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that the pixels values are actually standardized and the images are properly stored.\n",
    "for images, labels in train_ds.take(1):\n",
    "    print(images.shape, labels.shape)\n",
    "    img = images[0].numpy()\n",
    "    print(img.min(), img.max(), img.dtype, labels[0].numpy())\n",
    "    plt.imshow(img, cmap=plt.get_cmap(\"gray\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the test dataset. This dataset is not shuffled.\n",
    "# So you should see same values printed if you run it again.\n",
    "for images, labels in test_ds.take(1):\n",
    "    print(images.shape, labels.shape)\n",
    "    #img = images[0].numpy()\n",
    "    print(images[0].numpy().min(), images[0].numpy().max())\n",
    "    print(images[1].numpy().min(), images[1].numpy().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the file names can be matched with output of the test dataset\n",
    "test_ds_filelist = list_files_from_tfdataset(test_list_ds) # Create test dataset file list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in test_ds.take(1):\n",
    "    print(images.shape, labels.shape)\n",
    "    plt.imshow(images[2].numpy()[:,:], cmap=plt.get_cmap(\"gray\"))\n",
    "    print(images[2].numpy().shape, labels[2].numpy().shape)\n",
    "    print(labels[2].numpy())\n",
    "    print(test_ds_filelist[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if a batch of images from test dataset can be printed along with classnames and filenames\n",
    "plt.figure(figsize=(30, 30))\n",
    "cnt = 0\n",
    "for images, labels in train_ds.take(1):\n",
    "    #print(images.shape)\n",
    "    for i in range(batch_size):\n",
    "        ax = plt.subplot(int(np.sqrt(batch_size))+1, int(np.sqrt(batch_size))+1, i + 1)\n",
    "        #ax = plt.subplot(12, 12, i + 1)\n",
    "        #print(images[i].shape)\n",
    "        plt.imshow(images[i].numpy(), cmap=plt.get_cmap(\"gray\"))\n",
    "        #plt.title(class_names[labels[i]]+\"\\n\"+test_ds_filelist[i+cnt*batch_size].split(\"/\")[-1].replace(\".png\",\"\"))\n",
    "        plt.axis(\"off\")\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create keras model\n",
    "The input to the model is tf.data.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm current working directory\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create callbacks\n",
    "# This part is not complete. Needs to be done for later.\n",
    "\n",
    "# Reference for saving checkpoints and restarting from latest checkpoint\n",
    "# https://www.tensorflow.org/tutorials/keras/save_and_load\n",
    "\n",
    "#checkpoint_path = \"\"\n",
    "#checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, save_weights_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define model\n",
    "model=tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.InputLayer(input_shape=(img_height, img_width, 1)),\n",
    "        ###keras.layers.Conv2D(32,(3,3), activation='relu', input_shape=input_shape),\n",
    "        tf.keras.layers.Conv2D(32,(3,3),activation='relu'),\n",
    "        tf.keras.layers.MaxPool2D((2,2)),\n",
    "        tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
    "        tf.keras.layers.MaxPool2D(2,2),\n",
    "        tf.keras.layers.Conv2D(128,(3,3),activation='relu'),\n",
    "        tf.keras.layers.MaxPool2D(2,2),\n",
    "        tf.keras.layers.Conv2D(256,(3,3),activation='relu'),\n",
    "        tf.keras.layers.MaxPool2D(2,2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        #tf.keras.layers.Dense(1024, activation='relu'),\n",
    "        #tf.keras.layers.BatchNormalization(),\n",
    "        #tf.keras.layers.Dense(256, activation='relu'),\n",
    "        #tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "#Compile the model\n",
    "model.compile(\n",
    "              optimizer=opt, \n",
    "              #optimizer='adam', \n",
    "              loss='binary_crossentropy',\n",
    "              #loss='categorical_crossentropy',\n",
    "              metrics=['acc']\n",
    "              #metrics=['accuracy', 'f1score', 'precision', 'recall']\n",
    "             )\n",
    "\n",
    "#Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Visualize model graphically\n",
    "#tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scratch\n",
    "#epochs = 10000\n",
    "#steps_per_epoch = 1\n",
    "#num_batches = steps_per_epoch * epochs\n",
    "#print(\"Available images\",image_count-val_size)\n",
    "#print(\"Number of images required\", num_batches * batch_size)\n",
    "#(image_count-val_size)/68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Fitting the model\n",
    "history = model.fit(train_ds,\n",
    "                    #steps_per_epoch=100,#(image_count-val_size) // batch_size,\n",
    "                    epochs=100,\n",
    "                    #validation_steps=100,#val_size // batch_size,\n",
    "                    validation_data=val_ds,\n",
    "                    verbose=1\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model_filename = \"models/model.10dec2020.data_mip3_aug.per_image_dataset\"\n",
    "model_filename = \"models/model4.data_mip3_aug.std_dataset\"\n",
    "model.save(model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "acc_train = history.history['acc'][:num_epochs]\n",
    "acc_val = history.history['val_acc'][:num_epochs]\n",
    "epochs = range(1,num_epochs+1)\n",
    "plt.plot(epochs,acc_train, 'orange', label='training accuracy')\n",
    "plt.plot(epochs, acc_val, 'b', label= 'validation accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "loss_train = history.history['loss'][:num_epochs]\n",
    "loss_val = history.history['val_loss'][:num_epochs]\n",
    "epochs = range(1,num_epochs+1)\n",
    "plt.plot(epochs,loss_train, 'orange', label='training loss')\n",
    "plt.plot(epochs, loss_val, 'b', label= 'validation loss')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot images with true and predicted class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scratch\n",
    "#a = val_ds.list_files(\"*.png\")\n",
    "#len(list(val_ds.list_files(\"*\")))\n",
    "#dataset_length = [i for i,_ in enumerate(val_ds)][-1] + 1\n",
    "#dataset_length*batch_size\n",
    "for images, labels in test_ds.take(1):\n",
    "    print(images.shape, labels[0].numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_report(true_labels, pred_labels):\n",
    "    print(\"---Classification report---\\n\")\n",
    "    confusion_matrix = metrics.confusion_matrix(true_labels, pred_labels)\n",
    "    print(\"\\t\\t\\tClassified as\")\n",
    "    print(\"\\t\\t\"+\"\\t\".join(class_names)+\"\\tsum\")\n",
    "    for i in range(0,len(class_names)):\n",
    "        print(class_names[i]+\"\\t\"+\n",
    "              \"\\t\\t\".join([str(x) for x in confusion_matrix[i]])+\n",
    "              \"\\t\\t\"+str(np.sum(confusion_matrix[i])))\n",
    "    print(\"==========================================================\\n\")\n",
    "    print(\"F1 scores:\",metrics.f1_score(true_labels, pred_labels, average=None))\n",
    "    print(\"==========================================================\\n\")\n",
    "    print(\"metrics.classification_report:\\n\",metrics.classification_report(true_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_pred_labels(model, dataset, num_batches):\n",
    "    pred_1_to_10 = []\n",
    "    pred_labels = []\n",
    "    true_labels = []\n",
    "    cnt = 0\n",
    "    for images, labels in dataset.take(num_batches):\n",
    "        #3print(images.shape, labels.shape)\n",
    "        pred = model.predict(images)\n",
    "        pred_temp = (pred*10).astype(int)\n",
    "        #pred_temp = pred_temp.astype(int)\n",
    "        #print(pred.shape, pred[:5].astype(int))\n",
    "        #print(pred.shape)\n",
    "        for i in range(0,pred.shape[0]):\n",
    "            true_label = class_names[labels[i].numpy()]\n",
    "            pred_label = class_names[int(pred[i][0]>0.5)]\n",
    "            true_labels.append(true_label)\n",
    "            pred_labels.append(pred_label)\n",
    "            ##if true_label ==  'connection' and pred_label == 'no_connection':\n",
    "                # ???Save image- Saving image is still under review\n",
    "                #print(images[i].shape)\n",
    "                #print(type(image), image.shape, image.min(), image.max())\n",
    "                #img = Image.fromarray(np.array(255*image)).convert(\"L\")#\"RGB\")#(images[i].numpy())#.astype('uint8'))\n",
    "                #img.save(\"data_mip3/test_connection_as_noconnection/image_\"+str(cnt)+\".png\")\n",
    "                ##image = images[i].numpy()\n",
    "                ##image = np.squeeze(image)\n",
    "                ##image = images[5].astype('uint8')\n",
    "                ##Image.fromarray(images[6].astype('uint8')).save(\"image_6.png\")\n",
    "\n",
    "            pred_1_to_10.append(pred_temp[i])\n",
    "            cnt += 1\n",
    "    pred_1_to_10 = np.array(pred_1_to_10)\n",
    "    plt.hist(pred_1_to_10, bins=10) # This is to see histogram of predictions\n",
    "    true_labels = np.array(true_labels)\n",
    "    pred_labels = np.array(pred_labels)\n",
    "    print(true_labels.shape, pred_labels.shape)\n",
    "    print(\"Unique counts in true_labels:\", np.unique(true_labels, return_counts=True))\n",
    "    print(\"Unique counts in pred_labels:\", np.unique(pred_labels, return_counts=True))\n",
    "    print()\n",
    "    return(true_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report for test dataset\n",
    "true_labels, pred_labels = get_true_pred_labels(model, test_ds, 200)\n",
    "classification_report(true_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report for training dataset\n",
    "#true_labels, pred_labels = get_true_pred_labels(model, train_ds, 100)\n",
    "#classification_report(true_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report for validation dataset\n",
    "#true_labels, pred_labels = get_true_pred_labels(model, val_ds, 100)\n",
    "#classification_report(true_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
